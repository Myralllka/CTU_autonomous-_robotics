{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8b5cae",
   "metadata": {},
   "source": [
    "# ICP SLAM lab #\n",
    "\n",
    "This notebook is an overview about ICP and it's different implementations.\n",
    "\n",
    "## Contents:\n",
    "* [Overview](#Overview)\n",
    "* [ICP based on SVD](#ICP-based-on-SVD)\n",
    "* [Point to Plane Metric](#Point-to-Plane-Metric)\n",
    "* [Dealing with outliers](#Dealing-with-outliers)\n",
    "* [Real world Point CLouds](#Real-world-Point-CLouds)\n",
    "* [Occupancy Mapping](#Occupancy-Mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226db12c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Having two scans $P = \\{p_i\\}$ and $Q = \\{q_i\\}$ we want to find a transformation (rotation $R$ and translation $t$) to apply to $P$ to match $Q$ as good as possible. In the remainder of this notebook we will try to define what does \"as good as possible\" mean as well as ways to find such a transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from math import sin, cos, atan2, pi\n",
    "from IPython.display import display, Math, Latex, Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb590de",
   "metadata": {},
   "source": [
    "### Visualization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bd397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data_1, data_2, label_1, label_2, markersize_1=8, markersize_2=8):\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axis('equal')\n",
    "    if data_1 is not None:\n",
    "        x_p, y_p = data_1\n",
    "        ax.plot(x_p, y_p, color='red', markersize=markersize_1, marker='o', linestyle=\":\", label=label_1)\n",
    "    if data_2 is not None:\n",
    "        x_q, y_q = data_2\n",
    "        ax.plot(x_q, y_q, color='#336699', markersize=markersize_2, marker='o', linestyle=\":\", label=label_2)\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "def plot_values(values, label):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(values, label=label)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def animate_results(P_values, Q, corresp_values, xlim, ylim):\n",
    "    \"\"\"A function used to animate the iterative processes we use.\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    anim_ax = fig.add_subplot(111)\n",
    "    anim_ax.set(xlim=xlim, ylim=ylim)\n",
    "    anim_ax.set_aspect('equal')\n",
    "    plt.close()\n",
    "    x_q, y_q = Q\n",
    "    # draw initial correspondeces\n",
    "    corresp_lines = []\n",
    "    for i, j in correspondences:\n",
    "        corresp_lines.append(anim_ax.plot([], [], 'grey')[0])\n",
    "    # Prepare Q data.\n",
    "    Q_line, = anim_ax.plot(x_q, y_q, 'o', color='#336699')\n",
    "    # prepare empty line for moved data\n",
    "    P_line, = anim_ax.plot([], [], 'o', color='red')\n",
    "\n",
    "    def animate(i):\n",
    "        P_inc = P_values[i]\n",
    "        x_p, y_p = P_inc\n",
    "        P_line.set_data(x_p, y_p)\n",
    "        draw_inc_corresp(P_inc, Q, corresp_values[i])\n",
    "        return (P_line,)\n",
    "    \n",
    "    def draw_inc_corresp(points_from, points_to, correspondences):\n",
    "        for corr_idx, (i, j) in enumerate(correspondences):\n",
    "            x = [points_from[0, i], points_to[0, j]]\n",
    "            y = [points_from[1, i], points_to[1, j]]\n",
    "            corresp_lines[corr_idx].set_data(x, y)\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, animate,\n",
    "                                   frames=len(P_values), \n",
    "                                   interval=500, \n",
    "                                   blit=True)\n",
    "    return HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49633c02",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pertrubation rotation\n",
    "theta = pi / 4\n",
    "R_true = np.array([[cos(theta), -sin(theta)], \n",
    "                   [sin(theta),  cos(theta)]])\n",
    "t_true = np.array([[-2], [5]])\n",
    "\n",
    "# Generate data as a list of 2d points\n",
    "num_points = 30\n",
    "true_data = np.zeros((2, num_points))\n",
    "true_data[0, :] = range(0, num_points)\n",
    "true_data[1, :] = 0.2 * true_data[0, :] * np.sin(0.5 * true_data[0, :])\n",
    "\n",
    "# Move the data\n",
    "moved_data = R_true.dot(true_data) + t_true\n",
    "\n",
    "# Add noise\n",
    "n = 0.5 * (np.random.random((2, num_points)) - 0.5)  # noise\n",
    "moved_data = moved_data + n\n",
    "\n",
    "# Assign to variables we use in formulas.\n",
    "Q = true_data\n",
    "P = moved_data\n",
    "\n",
    "plot_data(moved_data, true_data, \"P: moved data\", \"Q: true data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650035a",
   "metadata": {},
   "source": [
    "### Correspondences computation\n",
    "We compute correspondences from $P$ to $Q$, i.e. for every $p_i$ we search the closest $q_j$ to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55139c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correspondences(P, Q):\n",
    "    \"\"\"For each point in P find closest one in Q.\"\"\"\n",
    "    p_size = P.shape[1]\n",
    "    q_size = Q.shape[1]\n",
    "    ids = []\n",
    "    dists = []\n",
    "    for i in range(p_size):\n",
    "        p_point = P[:, i]\n",
    "        min_dist = sys.maxsize\n",
    "        chosen_idx = -1\n",
    "        for j in range(q_size):\n",
    "            q_point = Q[:, j]\n",
    "            dist = np.linalg.norm(q_point - p_point)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                chosen_idx = j\n",
    "        ids.append(chosen_idx)\n",
    "        dists.append(min_dist)\n",
    "        \n",
    "    return dists, ids\n",
    "\n",
    "def draw_correspondeces(P, Q, correspondences, ax):\n",
    "    label_added = False\n",
    "    for i, j in correspondences:\n",
    "        x = [P[0, i], Q[0, j]]\n",
    "        y = [P[1, i], Q[1, j]]\n",
    "        if not label_added:\n",
    "            ax.plot(x, y, color='grey', label='correpondences')\n",
    "            label_added = True\n",
    "        else:\n",
    "            ax.plot(x, y, color='grey')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ab20b",
   "metadata": {},
   "source": [
    "## ICP based on SVD\n",
    "\n",
    "Tldr version. If the scans would match exactly, their cross-covariance would be identity. Therefore, we can iteratively optimize their cross-covariance to be as close as possible to an identity matrix by applying transformations to $P$. Let's dive into details. \n",
    "\n",
    "### Single iteration\n",
    "In a single iteration we assume that the correspondences are known. We can compute the cross-covariance between the corresponding points. Let $C = \\{\\{i,j\\}:p_i \\leftrightarrow q_j\\}$ be a set of all correspondences, also $|C| = N$. Then, the cross-covariance $H$ is computed as:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "H &=& E [(p_i - \\mu_P)(q_j - \\mu_Q)^T] \\\\\n",
    "&=& \\frac{1}{N}\\sum_{\\{i,j\\} \\in C}{(p_i - \\mu_P)(q_j - \\mu_Q)^T} \\\\\n",
    "&\\sim& \\sum_{\\{i,j\\} \\in C}{(p_i - \\mu_P)(q_j - \\mu_Q)^T}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Each point has two dimentions, that is $p_i, q_j \\in {\\rm I\\!R}^2$, thus cross-covariance has the form of (we drop indices $i$ and $j$ for notation simplicity):\n",
    "\n",
    "\\begin{equation}\n",
    "H =\n",
    "  \\begin{bmatrix}\n",
    "    cov(p_x, q_x) & cov(p_x, q_y) \\\\\n",
    "    cov(p_y, q_x) & cov(p_y, q_y)\n",
    "  \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "-----\n",
    "**Intuition:** Intuitevely, cross-covariance tells us how a coordinate of point $q$ changes with the change of $p$ coorinate, i.e. $cov(p_x, q_x)$ tells us how the $x$ coordinate of $q$ will change with the change in $x$ coordinate of $p$ given that the points are corresponding. Ideal cross-covariance matrix is an identity matrix, i.e., we want the $x$ coordinates to be ideally correlated between the scans $P$ and $Q$, while there should be no correlation between the $x$ coorinate of points from $P$ to the $y$ coordinate of points in $Q$. \n",
    "In our case, however, the position of $P$ is derived from the position of $Q$ through some rotation $R$ and translation $t$. Therefore, whenever we would move the scan $Q$, scan $P$ would move in a related way, but pertrubed through the rotation and translation applied, making the cross-covariance matrix non-identity.\n",
    "\n",
    "----\n",
    "\n",
    "Knowing the cross-covariance we can compute its SVD decomposition:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{SVD}(H) = USV^T\n",
    "\\end{equation}\n",
    "\n",
    "The SVD decomposition gives us how to rotate our data to align it with its prominent direction with $VU^T$ and how to scale it with its singular values $S$. Therefore:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "R &=& VU^T \\\\\n",
    "t &=& \\mu_Q - R \\mu_P\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### Let's try this out: ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e5856",
   "metadata": {},
   "source": [
    "### Make data centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_data(data, exclude_indices=[]):\n",
    "    reduced_data = np.delete(data, exclude_indices, axis=1)\n",
    "    center = np.expand_dims(reduced_data.mean(axis=1), 1)\n",
    "\n",
    "    return center, data - center\n",
    "\n",
    "center_of_P, P_centered = center_data(P.copy())\n",
    "center_of_Q, Q_centered = center_data(Q)\n",
    "ax = plot_data(P_centered, Q_centered,\n",
    "               label_1='Moved data centered', label_2='True data centered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a97485a",
   "metadata": {},
   "source": [
    "### Compute correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35aa8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists, ids = get_correspondences(P_centered, Q_centered)\n",
    "ax = plot_data(P_centered, Q_centered,\n",
    "               label_1='P centered', label_2='Q centered')\n",
    "correspondences = [(i, j) for i, j in zip(range(P.shape[1]), ids)]\n",
    "draw_correspondeces(P_centered, Q_centered, correspondences, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11c3d9",
   "metadata": {},
   "source": [
    "For efficiency reason, we encourage you to use `scipy` implementation of nearest neighbors search at your homework assignment. The `get_correspondences` function implementation is provided for comparison. Let's double check if it works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "dists, ids = get_correspondences(P_centered, Q_centered)\n",
    "\n",
    "tree = cKDTree(Q_centered.T)\n",
    "dists2, ids2 = tree.query(P_centered.T)\n",
    "\n",
    "print('Distances are same:', np.allclose(dists2, dists))\n",
    "print('Indixes are same:', np.allclose(ids, ids2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9cd968",
   "metadata": {},
   "source": [
    "### Compute covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6cfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_covariance(P_centered, Q_centered, correspondences):\n",
    "    # compute covariance matrix from point clouds\n",
    "    # note that you need to use corresponding points correctly (!)\n",
    "    \n",
    "    correspondences = np.array(correspondences)\n",
    "    \n",
    "    p_idxs = correspondences[:, 0]\n",
    "    q_idxs = correspondences[:, 1]\n",
    "\n",
    "    s = (P_centered[:, p_idxs]) @ (Q_centered[:, q_idxs]).T\n",
    "    \n",
    "    return s\n",
    "\n",
    "H = compute_cross_covariance(P_centered, Q_centered, correspondences)\n",
    "print(f'Covariance matrix: \\n {H}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945b2c5",
   "metadata": {},
   "source": [
    "### Get transformation from SVD decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_from_cov(H, center_of_P, center_of_Q):\n",
    "    # compute rotation and translation from covariance matrix and clouds centers\n",
    "    # NB: Numpy returns H = U * diag(s) * V, not U * diag(s) * V'.\n",
    "    U, S, Vh = np.linalg.svd(H, full_matrices=False)\n",
    "    \n",
    "    R = Vh.T @ U.T\n",
    "    t = center_of_Q - R @ center_of_P\n",
    "\n",
    "    return R, t\n",
    "\n",
    "R_found, t_found = get_transform_from_cov(H, center_of_P, center_of_Q)\n",
    "print(\"R_found =\\n\", R_found)\n",
    "print(\"t_found =\\n\", t_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa87823",
   "metadata": {},
   "source": [
    "### Apply a single correction to $P$ and visualize the result\n",
    "This is the result after just one iteration. Because our correspondences are not optimal, it is not a complete match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_found)\n",
    "print(R_found)\n",
    "P_corrected = np.matmul(R_found, P) + t_found\n",
    "ax = plot_data(P_corrected, Q, label_1='P corrected', label_2='Q')\n",
    "print(\"Squared diff: (P_corrected - Q) = \", np.linalg.norm(P_corrected - Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d43786",
   "metadata": {},
   "source": [
    "## Let's make it iterative\n",
    "If we would know the correct correspondences from the start, we would be able to get the optimal solution in a single iteration. This is rarely the case and we need to iterate. That consists of the following steps:\n",
    "\n",
    "1. Make data centered by subtracting the mean, $P_{centered}$ and $Q_{centered}$.\n",
    "2. For each point $P_i \\in P_{centered}$ find its correspondence $Q_i \\in Q_{centered}$.\n",
    "3. Compute the cross-covariance matrix using $P_{centered}$, $Q_{centered}$, and **the found correspondences**.\n",
    "4. Perform the SVD to find transformation that aligns the point clouds.\n",
    "5. Apply the found transformation to $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d04047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp(P, Q, iterations=10):\n",
    "    \"\"\"Perform ICP using SVD.\"\"\"\n",
    "    center_of_Q, Q_centered = center_data(Q)\n",
    "    inl_errs = []\n",
    "    P_values = [P.copy()]\n",
    "    P_corrected = P.copy()\n",
    "    \n",
    "    corresp_values = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # implement point-to-point ICP\n",
    "        \n",
    "        center_of_P, P_centered = center_data(P_corrected)\n",
    "        \n",
    "        dists, ids = get_correspondences(P_centered, Q_centered)\n",
    "        correspondences = [(i, j) for i, j in zip(range(P_centered.shape[1]), ids)]\n",
    "        \n",
    "        H = compute_cross_covariance(P_centered, Q_centered, correspondences)\n",
    "        \n",
    "        R_found, t_found = get_transform_from_cov(H, center_of_P, center_of_Q)\n",
    "        \n",
    "        P_corrected = np.matmul(R_found, P_corrected) + t_found\n",
    "        corresp_values.append(correspondences)\n",
    "        inl_errs.append(np.linalg.norm(P_corrected - Q))\n",
    "        P_values.append(P_corrected.copy())\n",
    "    corresp_values.append(correspondences)\n",
    "    return P_values, inl_errs, corresp_values\n",
    "\n",
    "P_values, inl_errs, corresp_values = icp(P, Q)\n",
    "plot_values(inl_errs, label=\"Squared diff P->Q\")\n",
    "ax = plot_data(P_values[-1], Q, label_1='P final', label_2='Q', markersize_1=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d56c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_results(P_values, Q, corresp_values, xlim=(-5, 35), ylim=(-5, 35))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb02a01",
   "metadata": {},
   "source": [
    "## Point to Plane Metric\n",
    "\n",
    "Point-to-point metric used before is not really the most optimal as can be seen above. It takes quite some iterations for the solution to converge. There is another metric which seems to work better. It is called \"point-to-plane\" metric. The idea here is that we still find the closest point, but the error is defined as a projection of the error onto the direction of the normal shot from the found point.\n",
    "\n",
    "The normal in this 2D case is simple to compute. For a vector $v = [x, y]^\\top$ the normal is a vector $n_v = [-y, x]^\\top$ as can be shown geometrically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d3e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normals(points, step=1):\n",
    "    normals = [np.array([[0, 0]])]\n",
    "    normals_at_points = []\n",
    "    for i in range(step, points.shape[1] - step):\n",
    "        prev_point = points[:, i - step]\n",
    "        next_point = points[:, i + step]\n",
    "        curr_point = points[:, i]\n",
    "        dx = next_point[0] - prev_point[0] \n",
    "        dy = next_point[1] - prev_point[1]\n",
    "        normal = np.array([[0, 0],[-dy, dx]])\n",
    "        normal = normal / np.linalg.norm(normal)\n",
    "        normals.append(normal[[1], :])  \n",
    "        normals_at_points.append(normal + curr_point)\n",
    "    normals.append(np.array([[0, 0]]))\n",
    "    return normals, normals_at_points\n",
    "\n",
    "def plot_normals(normals, ax):\n",
    "    label_added = False\n",
    "    for normal in normals:\n",
    "        if not label_added:\n",
    "            ax.plot(normal[:,0], normal[:,1], color='grey', label='normals')\n",
    "            label_added = True\n",
    "        else:\n",
    "            ax.plot(normal[:,0], normal[:,1], color='grey')\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "Q_normals, Q_normals_to_draw = compute_normals(Q)\n",
    "ax = plot_data(None, Q, None, 'Q')\n",
    "ax = plot_normals(Q_normals_to_draw, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2ffd2",
   "metadata": {},
   "source": [
    "### ICP with point-to-plane metric\n",
    "\n",
    "The ICP algorithm with point-to-plane metric that we are implementing is quite similar to the one with point-to-point:\n",
    "\n",
    "1. Make data centered by subtracting the mean, $P_{centered}$ and $Q_{centered}$.\n",
    "2. For each point $p_i \\in P_{centered}$ find its correspondence $q_j \\in Q_{centered}$.\n",
    "3. For each point in $p_i \\in P_{centered}$ find location of its projection on surface of $Q_{centered}$ defined by corresponding neighbor normal. We will call this projection cloud $Q_{centered}^{plane}$. The projection point is denoted as $q_j^{plane} \\in Q_{centered}^{plane}$.\n",
    "4. Compute the cross-covariance matrix using $P_{centered}$, $Q_{centered}^{plane}$, and **the found correspondences**.\n",
    "5. Perform the SVD to find transformation that aligns the point clouds.\n",
    "6. Apply the found transformation to $P$.\n",
    "\n",
    "![](./icp_point2plane.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp_normals(P, Q, iterations=10):\n",
    "    \"\"\"Perform ICP using SVD.\"\"\"\n",
    "    center_of_Q, Q_centered = center_data(Q)\n",
    "    inl_errs = []\n",
    "    P_values = [P.copy()]\n",
    "    P_corrected = P.copy()\n",
    "    corresp_values = []\n",
    "    Q_normals, _ = compute_normals(Q_centered)\n",
    "    Q_normals = np.array(Q_normals).squeeze().T\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # implement point-to-plane ICP\n",
    "        \n",
    "        center_of_P, P_centered = center_data(P_corrected)\n",
    "        _, ids = get_correspondences(P_centered, Q_centered)\n",
    "        correspondences = [(i, j) for i, j in zip(range(P_centered.shape[1]), ids)]\n",
    "\n",
    "        dists = np.diag(Q_normals.T @ (P_centered - Q_centered))\n",
    "\n",
    "        Q_plane = P_centered - dists * Q_normals\n",
    "        \n",
    "        H = compute_cross_covariance(P_centered, Q_plane, correspondences)\n",
    "        \n",
    "        R_found, t_found = get_transform_from_cov(H, center_of_P, center_of_Q)\n",
    "        P_corrected = np.matmul(R_found, P_corrected) + t_found\n",
    "        \n",
    "        corresp_values.append(correspondences)\n",
    "        inl_errs.append(np.linalg.norm(P_corrected - Q))\n",
    "        P_values.append(P_corrected.copy())\n",
    "        \n",
    "    corresp_values.append(correspondences)\n",
    "    return P_values, inl_errs, corresp_values\n",
    "\n",
    "P_values, inl_errs, corresp_values = icp_normals(P, Q)\n",
    "plot_values(inl_errs, label=\"Squared diff P->Q_plane\")\n",
    "\n",
    "ax = plot_data(P_values[-1], Q, label_1='P final', label_2='Q', markersize_1=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e66273",
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_results(P_values, Q, corresp_values, xlim=(-5, 35), ylim=(-10, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679acb8d",
   "metadata": {},
   "source": [
    "# Dealing with outliers\n",
    "If we corrupt our data, it gets harder for all of these algorithms to reason about it. \n",
    "\n",
    "Let's say, there is a couple pretty bad outliers in the $P$ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce outliers\n",
    "P_outliers = P.copy()\n",
    "P_outliers[:, 10] = np.array([-10, 30])\n",
    "P_outliers[:, 20] = np.array([0, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcf8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_of_P_outliers = np.array([P_outliers.mean(axis=1)]).T\n",
    "center_of_Q = np.array([Q.mean(axis=1)]).T\n",
    "P_centered_outliers = P_outliers - center_of_P_outliers\n",
    "Q_centered = Q - center_of_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists, ids = get_correspondences(P_centered_outliers, Q_centered)\n",
    "correspondences = [(i, j) for i, j in zip(range(P_centered_outliers.shape[1]), ids)]\n",
    "ax = plot_data(P_centered_outliers, Q_centered,\n",
    "               label_1='P centered', label_2='Q centered')\n",
    "draw_correspondeces(P_centered_outliers, Q_centered, correspondences, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39666b7f",
   "metadata": {},
   "source": [
    "## We cannot just run our methods without modification\n",
    "If we try to run any of the methods above without modification, they will fail as the outliers will \"drag\" the solution away from the one that looks visually the best. That is because the outliers generate quite a big error that becomes part of the optimization process, which tries to satisfy these new constraints.\n",
    "\n",
    "#### Let's see what will happen if we just use the vanilla point-to-point ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_values, inl_errs, corresp_values = icp(P_outliers, Q)\n",
    "plot_values(inl_errs, label=\"Squared diff P->Q\")\n",
    "animate_results(P_values, Q, corresp_values, xlim=(-5, 35), ylim=(-10, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8cefb9",
   "metadata": {},
   "source": [
    "## Outliers rejection\n",
    "\n",
    "SVD-based ICP has two steps: centering the data using its mean and optimizing the rotation. Let's looks at both starting with the rotational part.\n",
    "\n",
    "#### Rotational part\n",
    "\n",
    "It is relatively simple to remove the outliers during the rotation optimization. Each point contributes to the update of the cross-covariance matrix. We can exclude points that are too far apart from contributing to the update of the cross-covariance matrix, thus, removing them from the optimization. \n",
    "\n",
    "#### Translational part\n",
    "\n",
    "This is the tricky part. As centering the data happens *before* we estimate correspondences and we define the outliers by the length of the correspondence, there is no way to know which of the data points are outliers. If we do nothing about it, we will *always* have a drift after the optimization. We could do the following:\n",
    "\n",
    "- Find the first mean as if there were no outliers\n",
    "- While performing rotation on that iteration, mark the points that are outliers (now we have correspondences and can do this)\n",
    "- Apply the found rotation and translation\n",
    "- Repeat the procedure excluding the marked outlier points from computing the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp(P, Q, iterations=10, dist_th=10.0):\n",
    "    \"\"\"Perform ICP using SVD.\"\"\"\n",
    "    center_of_Q, Q_centered = center_data(Q)\n",
    "    inl_errs = []\n",
    "    P_values = [P.copy()]\n",
    "    P_copy = P.copy()\n",
    "    corresp_values = []\n",
    "    inl_mask = []\n",
    "    \n",
    "    # : use only inlier points to compute clouds means\n",
    "    exclude_indices = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "\n",
    "        center_of_P, P_centered = center_data(P_copy, exclude_indices=exclude_indices)\n",
    "\n",
    "        dists, ids = get_correspondences(P_centered, Q_centered)\n",
    "        correspondences = np.array([(i, j) for i, j in zip(range(P_centered.shape[1]), ids)])\n",
    "        \n",
    "        # : outlier rejection. Reject correspondencies which are too far away.\n",
    "        \n",
    "        inl_mask = np.array(dists) < 5\n",
    "        exclude_indices = np.bitwise_not(inl_mask)\n",
    "        \n",
    "        \n",
    "        correspondences = np.asarray(correspondences)[inl_mask]\n",
    "        dists = np.asarray(dists)[inl_mask]\n",
    "        \n",
    "        H = compute_cross_covariance(P_centered, Q_centered, correspondences)\n",
    "        R, t = get_transform_from_cov(H, center_of_P, center_of_Q)\n",
    "        \n",
    "        P_copy = R.dot(P_copy) + t\n",
    "        P_values.append(P_copy)\n",
    "        \n",
    "        inl_errs.append(np.linalg.norm(P_copy - Q))\n",
    "        corresp_values.append(correspondences)\n",
    "        \n",
    "    corresp_values.append(correspondences)\n",
    "    \n",
    "    return P_values, inl_errs, corresp_values\n",
    "\n",
    "P_values, inl_errs, corresp_values = icp(P_outliers, Q)\n",
    "# P_values, inl_errs, corresp_values = icp(P, Q)\n",
    "plot_values(inl_errs, label=\"Squared diff P->Q\")\n",
    "animate_results(P_values, Q, corresp_values, xlim=(-5, 35), ylim=(-10, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47155036",
   "metadata": {},
   "source": [
    "## Real world Point CLouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90425d",
   "metadata": {},
   "source": [
    "Import Open3D library: http://www.open3d.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f51222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install open3d\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99687c8",
   "metadata": {},
   "source": [
    "Download point cloud scans and their 6DoF poses in an environment.\n",
    "\n",
    "The data set contains point cloud data captured in an indoor environment with precise localization and ground truth mapping information. Two ”stop-and-go” data sequences of a robot with mounted Ouster OS1-128 lidar are provided.\n",
    "For more information about the data, please, refer to https://paperswithcode.com/dataset/fee-corridor.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18803de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'\n",
    "id1, id2 = '1669300991_618086656', '1669301026_319255296'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    url = 'http://ptak.felk.cvut.cz/vras/data/fee_corridor/sequences/seq2'\n",
    "    os.system('wget %s/poses/poses.csv -P %s' % (url, path))\n",
    "    os.system('wget %s/ouster_points/%s.npz -P %s' % (url, id1, path))\n",
    "    os.system('wget %s/ouster_points/%s.npz -P %s' % (url, id2, path))\n",
    "    os.system('wget https://github.com/AtsushiSakai/PythonRobotics/raw/master/Mapping/lidar_to_grid_map/lidar01.csv -P %s' % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31c897",
   "metadata": {},
   "source": [
    "### Helper functions to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_poses(path):\n",
    "    poses = np.genfromtxt(path, delimiter=', ', skip_header=True)\n",
    "    ids = np.genfromtxt(path, delimiter=', ', dtype=str, skip_header=True)[:, 0].tolist()\n",
    "    poses = poses[:, 2:]\n",
    "    poses = poses.reshape((-1, 4, 4))\n",
    "    poses = dict(zip(ids, poses))\n",
    "    return poses\n",
    "\n",
    "def read_cloud(npz_file):\n",
    "    cloud = np.load(npz_file)['cloud']\n",
    "    if cloud.ndim == 2:\n",
    "        cloud = cloud.reshape((-1,))\n",
    "    return cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653247ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cloud poses\n",
    "poses = read_poses(os.path.join(path, 'poses.csv'))\n",
    "pose1 = poses[id1]\n",
    "pose2 = poses[id2]\n",
    "\n",
    "# load point clouds\n",
    "cloud1 = read_cloud(os.path.join(path, '%s.npz' % id1))\n",
    "cloud2 = read_cloud(os.path.join(path, '%s.npz' % id2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93ee20",
   "metadata": {},
   "source": [
    "### Visualize point cloud with Open3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a303f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.recfunctions import structured_to_unstructured, unstructured_to_structured\n",
    "\n",
    "def visualize_clouds(clouds, colors=None, show_normals=False):\n",
    "    if colors:\n",
    "        assert len(colors) == len(clouds)\n",
    "    geoms = []\n",
    "    for i, cloud in enumerate(clouds):\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        points = structured_to_unstructured(cloud[['x', 'y', 'z']])\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        if colors:\n",
    "            pcd.colors = o3d.utility.Vector3dVector(colors[i])\n",
    "        if show_normals:\n",
    "            normals = structured_to_unstructured(cloud[['normal_x', 'normal_y', 'normal_z']])\n",
    "            pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "        geoms.append(pcd)\n",
    "    o3d.visualization.draw_geometries(geoms, point_show_normal=show_normals)\n",
    "    \n",
    "    \n",
    "# matplotlib visualization version\n",
    "def visualize_clouds_2d(P, Q, **kwargs):\n",
    "    if P.dtype.names:\n",
    "        P = structured_to_unstructured(P[['x', 'y', 'z']])\n",
    "    if Q.dtype.names:\n",
    "        Q = structured_to_unstructured(Q[['x', 'y', 'z']])\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(P[:, 0], P[:, 1], 'o', label='source cloud', **kwargs)\n",
    "    plt.plot(Q[:, 0], Q[:, 1], 'x', label='target cloud', **kwargs)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7aa2e2",
   "metadata": {},
   "source": [
    "Use the following keyboard shortcuts to interact with the visualized cloud\n",
    "\n",
    "```\n",
    "-- Mouse view control --\n",
    "  Left button + drag         : Rotate.\n",
    "  Ctrl + left button + drag  : Translate.\n",
    "  Wheel button + drag        : Translate.\n",
    "  Shift + left button + drag : Roll.\n",
    "  Wheel                      : Zoom in/out.\n",
    "\n",
    "-- Keyboard view control --\n",
    "  [/]          : Increase/decrease field of view.\n",
    "  R            : Reset view point.\n",
    "  Ctrl/Cmd + C : Copy current view status into the clipboard.\n",
    "  Ctrl/Cmd + V : Paste view status from clipboard.\n",
    "\n",
    "-- General control --\n",
    "  Q, Esc       : Exit window.\n",
    "  H            : Print help message.\n",
    "  P, PrtScn    : Take a screen capture.\n",
    "  D            : Take a depth capture.\n",
    "  O            : Take a capture of current rendering settings.\n",
    "```\n",
    "\n",
    "Reference: http://www.open3d.org/docs/release/tutorial/visualization/visualization.html#Function-draw_geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb70728",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clouds([cloud1], show_normals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd26de",
   "metadata": {},
   "source": [
    "### Pair of scans Before alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a29270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# green color for first point cloud and blue for the second scan\n",
    "colors=[np.zeros((len(cloud1), 3)) + np.array([0, 1, 0]),\n",
    "        np.zeros((len(cloud2), 3)) + np.array([0, 0, 1])]\n",
    "\n",
    "visualize_clouds([cloud1, cloud2], colors)\n",
    "visualize_clouds_2d(cloud1, cloud2, markersize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9765d9",
   "metadata": {},
   "source": [
    "### Aligned clouds with Transformation from data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth transformation that aligns the point clouds (from data set)\n",
    "Tr_gt = np.matmul(np.linalg.inv(pose2), pose1)\n",
    "print(Tr_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cloud(Tr, cloud):\n",
    "    cloud_tr = cloud.copy()\n",
    "    points = structured_to_unstructured(cloud[['x', 'y', 'z']])\n",
    "    points_tr = np.matmul(points, Tr[:3, :3].T) + Tr[:3, 3:].T\n",
    "    cloud_tr[['x', 'y', 'z']] = unstructured_to_structured(points_tr, names=['x', 'y', 'z'])\n",
    "    return cloud_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud1_tr = transform_cloud(Tr_gt, cloud1)\n",
    "\n",
    "visualize_clouds([cloud1_tr, cloud2], colors=colors)\n",
    "visualize_clouds_2d(cloud1_tr, cloud2, markersize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c7fbf",
   "metadata": {},
   "source": [
    "### HW04\n",
    "\n",
    "Implement `absolute_orientation` and `icp` functions in `aro_slam/icp.py` module. Feel free to use `icp_demo` function to test your implementation with the 3D point cloud scans from FEE Corridor:\n",
    "\n",
    "```python\n",
    "python -m aro_slam.icp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35977968",
   "metadata": {},
   "source": [
    "## Occupancy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897562a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scan(f):\n",
    "    \"\"\"\n",
    "    Reading LIDAR laser beams (angles and corresponding distance data)\n",
    "    \"\"\"\n",
    "    with open(f) as data:\n",
    "        measures = [line.split(\",\") for line in data]\n",
    "    angles = []\n",
    "    distances = []\n",
    "    for measure in measures:\n",
    "        angles.append(float(measure[0]))\n",
    "        distances.append(float(measure[1]))\n",
    "    angles = np.array(angles)\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    return angles, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles, distances = read_scan('./data/lidar01.csv')\n",
    "angles[:5], distances[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319a046",
   "metadata": {},
   "source": [
    "### Bresenham's Line Algorithm\n",
    "\n",
    "Reference: https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham(start, end):\n",
    "    \"\"\"\n",
    "    Implementation of Bresenham's line drawing algorithm\n",
    "    See en.wikipedia.org/wiki/Bresenham's_line_algorithm\n",
    "    Bresenham's Line Algorithm\n",
    "    Produces a np.array from start and end (original from roguebasin.com)\n",
    "    >>> points1 = bresenham((4, 4), (6, 10))\n",
    "    >>> print(points1)\n",
    "    np.array([[4,4], [4,5], [5,6], [5,7], [5,8], [6,9], [6,10]])\n",
    "    \"\"\"\n",
    "    # setup initial conditions\n",
    "    x1, y1 = start\n",
    "    x2, y2 = end\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    is_steep = abs(dy) > abs(dx)  # determine how steep the line is\n",
    "    if is_steep:  # rotate line\n",
    "        x1, y1 = y1, x1\n",
    "        x2, y2 = y2, x2\n",
    "    # swap start and end points if necessary and store swap state\n",
    "    swapped = False\n",
    "    if x1 > x2:\n",
    "        x1, x2 = x2, x1\n",
    "        y1, y2 = y2, y1\n",
    "        swapped = True\n",
    "    dx = x2 - x1  # recalculate differentials\n",
    "    dy = y2 - y1  # recalculate differentials\n",
    "    error = int(dx / 2.0)  # calculate error\n",
    "    y_step = 1 if y1 < y2 else -1\n",
    "    # iterate over bounding box generating points between start and end\n",
    "    y = y1\n",
    "    points = []\n",
    "    for x in range(x1, x2 + 1):\n",
    "        coord = [y, x] if is_steep else (x, y)\n",
    "        points.append(coord)\n",
    "        error -= abs(dy)\n",
    "        if error < 0:\n",
    "            y += y_step\n",
    "            error += dx\n",
    "    if swapped:  # reverse the list if the coordinates were swapped\n",
    "        points.reverse()\n",
    "    points = np.array(points)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85277d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTEND_AREA = 1.0\n",
    "\n",
    "def calc_grid_map_config(ox, oy, xy_resolution):\n",
    "    \"\"\"\n",
    "    Calculates the size, and the maximum distances according to the the\n",
    "    measurement center\n",
    "    \"\"\"\n",
    "    min_x = round(min(ox) - EXTEND_AREA / 2.0)\n",
    "    min_y = round(min(oy) - EXTEND_AREA / 2.0)\n",
    "    max_x = round(max(ox) + EXTEND_AREA / 2.0)\n",
    "    max_y = round(max(oy) + EXTEND_AREA / 2.0)\n",
    "    xw = int(round((max_x - min_x) / xy_resolution))\n",
    "    yw = int(round((max_y - min_y) / xy_resolution))\n",
    "    print(\"The grid map is \", xw, \"x\", yw, \".\")\n",
    "    \n",
    "    return min_x, min_y, max_x, max_y, xw, yw\n",
    "\n",
    "\n",
    "def atan_zero_to_twopi(y, x):\n",
    "    angle = math.atan2(y, x)\n",
    "    if angle < 0.0:\n",
    "        angle += math.pi * 2.0\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7882d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ray_casting_grid_map(ox, oy, xy_resolution):\n",
    "\n",
    "    min_x, min_y, max_x, max_y, x_w, y_w = calc_grid_map_config(ox, oy, xy_resolution)\n",
    "    \n",
    "    # default 0.5 -- [[0.5 for i in range(y_w)] for i in range(x_w)]\n",
    "    occupancy_map = np.ones((x_w, y_w)) / 2\n",
    "    \n",
    "    center_x = int(round(-min_x / xy_resolution))  # center x coordinate of the grid map\n",
    "    center_y = int(round(-min_y / xy_resolution))  # center y coordinate of the grid map\n",
    "    \n",
    "    # occupancy grid computed with bresenham ray casting\n",
    "    for (x, y) in zip(ox, oy):\n",
    "        # x coordinate of the the occupied area\n",
    "        ix = int(round((x - min_x) / xy_resolution))\n",
    "        # y coordinate of the the occupied area\n",
    "        iy = int(round((y - min_y) / xy_resolution))\n",
    "        laser_beams = bresenham((center_x, center_y), (\n",
    "            ix, iy))  # line form the lidar to the occupied point\n",
    "        for laser_beam in laser_beams:\n",
    "            occupancy_map[laser_beam[0]][\n",
    "                laser_beam[1]] = 0.0  # free area 0.0\n",
    "        occupancy_map[ix][iy] = 1.0  # occupied area 1.0\n",
    "        occupancy_map[ix + 1][iy] = 1.0  # extend the occupied area\n",
    "        occupancy_map[ix][iy + 1] = 1.0  # extend the occupied area\n",
    "        occupancy_map[ix + 1][iy + 1] = 1.0  # extend the occupied area\n",
    "\n",
    "    return occupancy_map, min_x, max_x, min_y, max_y, xy_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_resolution = 0.02  # x-y grid resolution\n",
    "ang, dist = read_scan(\"./data/lidar01.csv\")\n",
    "\n",
    "ox = np.sin(ang) * dist\n",
    "oy = np.cos(ang) * dist\n",
    "\n",
    "occupancy_map, min_x, max_x, min_y, max_y, xy_resolution = \\\n",
    "    generate_ray_casting_grid_map(ox, oy, xy_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_res = np.array(occupancy_map).shape\n",
    "\n",
    "plt.figure(1, figsize=(20, 10))\n",
    "plt.subplot(122)\n",
    "plt.imshow(occupancy_map, cmap=\"PiYG_r\")\n",
    "# cmap = \"binary\" \"PiYG_r\" \"PiYG_r\" \"bone\" \"bone_r\" \"RdYlGn_r\"\n",
    "plt.clim(-0.4, 1.4)\n",
    "plt.gca().set_xticks(np.arange(-.5, xy_res[1], 1), minor=True)\n",
    "plt.gca().set_yticks(np.arange(-.5, xy_res[0], 1), minor=True)\n",
    "plt.grid(True, which=\"minor\", color=\"w\", linewidth=0.6, alpha=0.5)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot([oy, np.zeros(np.size(oy))], [ox, np.zeros(np.size(oy))], \"ro-\")\n",
    "plt.axis(\"equal\")\n",
    "plt.plot(0.0, 0.0, \"ob\")\n",
    "plt.gca().set_aspect(\"equal\", \"box\")\n",
    "bottom, top = plt.ylim()  # return the current y-lim\n",
    "plt.ylim((top, bottom))  # rescale y axis, to match the grid orientation\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fc0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
